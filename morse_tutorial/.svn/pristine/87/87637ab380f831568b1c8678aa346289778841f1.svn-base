HIPS (Hierarchical Iterative Parallel Solver) is a scientific library
that provides an efficient parallel iterative solver for very large
sparse linear systems, see http://hips.gforge.inria.fr/.

This library depends on partitioners (Metis or Scotch), BLAS and MPI.

Spack helps us to automatically build and install all components
required in a coherent way ensuring compatibility of variants and
options.

Here is an overview of the dependency DAG of HiPS:
#+attr_html: :width 640px
[[file:figures/hips_dep.png]]

* HiPS package options overview

Use the ~spack info~ command to get some information about the HiPS
package
#+BEGIN_SRC sh :session spack :exports code :results none
spack info hips
#+END_SRC

Pay attention to:
- the versions available, releases or git/svn branches,
- the variants you can build and the default variants chosen

* HiPS versions available

Releases available are denoted with integers and are considered to be
more stable versions.
#+BEGIN_SRC sh :session spack :exports code :results none
spack spec hips@1.2b-rc5
#+END_SRC

To use an existing installation of HiPS in your stack choose the
"exist" version. This option requires to set an environment variable,
HIPS_DIR, pointing to the installation path of your HiPS
#+BEGIN_SRC sh :session spack :exports code :results none
export HIPS_DIR=/path/to/your/hips/installation
spack spec hips@exist
#+END_SRC

If you plan to use spack when developing into HiPS, you can
indicate to spack to build HiPS in your own source directory, to
be set in HIPS_DIR, containing your modifications
#+BEGIN_SRC sh :session spack :exports code :results none
export HIPS_DIR=/path/to/your/hips/sources
spack spec hips@src
#+END_SRC

You can also imagine you want to modify some source files of Scotch
and test your modifications through HiPS
#+BEGIN_SRC sh :session spack :exports code :results none
export SCOTCH_DIR=/path/to/your/scotch/sources
spack install hips ^scotch@src
#+END_SRC
You can then make new modifications and re-build your Scotch libraries
#+BEGIN_SRC sh :session spack :exports code :results none
spack uninstall -f scotch@src
spack install scotch@src
#+END_SRC
If Scotch is built as shared libraries HiPS drivers will use the
newly generated libraries. If Scotch libraries are static, it is
required to re-generate HiPS drivers.
#+BEGIN_SRC sh :session spack :exports code :results none
spack uninstall hips ^scotch@src~shared
spack uninstall scotch@src~shared
spack install hips ^scotch@src~shared
#+END_SRC

* HiPS as static or dynamic libraries

HiPS produces static libraries by default because variant
~shared is enabled.
#+BEGIN_SRC sh :session spack :exports code :results none
spack spec hips # is identical to
spack spec hips~shared
#+END_SRC

The dynamic variant is not available for now.
# To build a static version of HiPS use ~shared
# #+BEGIN_SRC sh :session spack :exports code :results none
# spack spec chameleon~shared
# #+END_SRC

* HiPS with or without drivers

HiPS produces examples (plus testers and timers) by default
because variant +examples is enabled.
#+BEGIN_SRC sh :session spack :exports code :results none
spack spec hips # is identical to
spack spec hips+examples
#+END_SRC

To disable the builling of examples use ~examples
#+BEGIN_SRC sh :session spack :exports code :results none
spack spec hips~examples
#+END_SRC

* HiPS depends on BLAS, MKL

HiPS depends on dense computational kernels for execution on
conventional CPUs which is BLAS.

When you invoke the following spack command
#+BEGIN_SRC sh :session spack :exports code :results none
spack spec hips
#+END_SRC
you can notice that the default stack requires BLAS to be installed.
This library is seen in spack as a virtual package in the sense that
several implementations of this interface exists and can be chosen. By
default, eigen is chosen for BLAS. Other choices can be made by
specifying it through an spack command. First you can look for the
available /providers/ of a virtual package by using the command ~spack
providers~.

#+BEGIN_EXAMPLE
spack providers blas
#+END_EXAMPLE
The default behaviour follows a lexicographical logic on the package
names. For example, eigen-blas is chosen by default because "e" comes
before the "m" of mkl-blas, the "n" of netlib-blas and the "o" of
openblas.

You can specify the implementation you want to use in your stack with
the ^ character
#+BEGIN_SRC sh :session spack :exports code :results none
spack spec hips ^openblas
#+END_SRC

** How to use the kernels available in the Intel MKL

For proprietary softwares such as the Intel MKL, we do not provide the
installation but we can use them if available in the environment.  For
example if you have an Intel suite installed on your system, make it
available in the environment and our packages in Spack can use it in
the stack.  More precisely we need the environment variable MKLROOT to
be set to use kernels available in the MKL (this is quite
standard). On my labtop for example
#+BEGIN_SRC sh :session spack :exports code :results none
source /home/pruvost/intel/bin/compilervars.sh intel64
source /home/pruvost/intel/mkl/bin/mklvars.sh intel64
#+END_SRC

Then because the MKLROOT is set we can use the MKL kernels
#+BEGIN_SRC sh :session spack :exports code :results none
spack spec hips ^mkl-blas
#+END_SRC

* HiPS depends on METIS or Scotch

HiPS depends on a partitioning library. The choices available are
Metis and Scotch. These variants are mutually exclusive. Choose either
Metis or Scotch in your stack. By default Scotch is chosen so that
#+BEGIN_SRC sh :session spack :exports code :results none
spack spec hips # is identical to
spack spec hips~metis
#+END_SRC
will build a stack with Scotch.

To use Metis instead use the variant +metis.
#+BEGIN_SRC sh :session spack :exports code :results none
spack spec hips+metis
#+END_SRC

* HiPS depends on MPI

HiPS can be executed on clusters of interconnected nodes using
the MPI library.

Notice that we depend on the MPI virtual package here.
To get a list of MPI packages available, try the following:
#+BEGIN_SRC sh :session spack :exports code :results none
spack providers mpi
#+END_SRC

To chose your MPI implementation, use the ^ character
#+BEGIN_SRC sh :session spack :exports code :results none
spack spec hips ^mpich
spack spec hips ^openmpi
#+END_SRC

** How to use IntelMPI
For IntelMPI we do not provide the installation but we can use it if
available in the environment.  For example if you have an Intel suite
installed on your system, make it available in the environment.
More precisely set I_MPI_ROOT.  On my labtop for example:
#+BEGIN_SRC sh :session spack :exports code :results none
source /home/pruvost/intel/bin/compilervars.sh intel64
source /home/pruvost/intel/impi/5.0.1.035/bin64/mpivars.sh
spack spec hips %intel ^mkl-blas ^intelmpi
#+END_SRC
Be aware that to use IntelMPI, you should use the intel compiler. This
can be set with %intel. Remember you should have defined your
compilers first. Check that it is available
#+BEGIN_SRC sh :session spack :exports code :results none
spack compiler list
#+END_SRC
If not add it
#+BEGIN_SRC sh :session spack :exports code :results none
spack compiler add /path/to/your/intel/compilers
#+END_SRC
You can also edit the file ~$HOME/.spack/compilers.yaml~ to add/remove
compilers or with ~spack config edit compilers~ command.
* Troubleshouting
** Mac OS X
- malloc.h does not exist: ~./io_hb.h:8:9: fatal error: 'malloc.h' file not found~
